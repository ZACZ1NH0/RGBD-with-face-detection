{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8921ea0",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-11T09:52:53.334952Z",
     "iopub.status.busy": "2025-12-11T09:52:53.334636Z",
     "iopub.status.idle": "2025-12-11T09:53:02.551199Z",
     "shell.execute_reply": "2025-12-11T09:53:02.550489Z"
    },
    "papermill": {
     "duration": 9.222046,
     "end_time": "2025-12-11T09:53:02.552657",
     "exception": false,
     "start_time": "2025-12-11T09:52:53.330611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.transforms import RandomResizedCrop\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "class RGBDepthDataset(Dataset):\n",
    "    def __init__(self, rgb_dir, depth_dir, image_size=128):\n",
    "        self.rgb_dir = rgb_dir\n",
    "        self.depth_dir = depth_dir\n",
    "        self.image_size = image_size\n",
    "\n",
    "        # Lấy danh sách file (không lấy đuôi)\n",
    "        rgb_files = sorted(os.listdir(rgb_dir))\n",
    "        depth_files = sorted(os.listdir(depth_dir))\n",
    "\n",
    "        rgb_ids = set([f.split('.')[0] for f in rgb_files])\n",
    "        depth_ids = set([f.split('.')[0] for f in depth_files])\n",
    "\n",
    "        # Tên file xuất hiện trong cả RGB và Depth\n",
    "        self.ids = sorted(list(rgb_ids.intersection(depth_ids)))\n",
    "\n",
    "        print(\"Total matched pairs:\", len(self.ids))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def augment_pair(self, rgb, depth):\n",
    "        i, j, h, w = RandomResizedCrop.get_params(\n",
    "            img=rgb, scale=(0.8, 1.0), ratio=(0.9, 1.1)\n",
    "        )\n",
    "\n",
    "        rgb = TF.resized_crop(rgb, i, j, h, w, size=(self.image_size, self.image_size))\n",
    "        depth = TF.resized_crop(depth, i, j, h, w, size=(self.image_size, self.image_size))\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            rgb = TF.hflip(rgb)\n",
    "            depth = TF.hflip(depth)\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            rgb = TF.adjust_brightness(rgb, random.uniform(0.8, 1.2))\n",
    "            rgb = TF.adjust_contrast(rgb, random.uniform(0.8, 1.2))\n",
    "\n",
    "        return rgb, depth\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name = self.ids[idx]\n",
    "        rgb_path = os.path.join(self.rgb_dir, name + \".jpg\")\n",
    "        depth_path = os.path.join(self.depth_dir, name + \".jpg\")\n",
    "\n",
    "        rgb = Image.open(rgb_path).convert(\"RGB\")\n",
    "        depth = Image.open(depth_path).convert(\"L\")\n",
    "\n",
    "        # Augment 2 views\n",
    "        rgb1, depth1 = self.augment_pair(rgb, depth)\n",
    "        rgb2, depth2 = self.augment_pair(rgb, depth)\n",
    "\n",
    "        # To tensor\n",
    "        rgb1 = TF.to_tensor(rgb1)\n",
    "        rgb2 = TF.to_tensor(rgb2)\n",
    "        depth1 = TF.to_tensor(depth1)\n",
    "        depth2 = TF.to_tensor(depth2)\n",
    "\n",
    "        return rgb1, rgb2, depth1, depth2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04938e62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T09:53:02.557592Z",
     "iopub.status.busy": "2025-12-11T09:53:02.557244Z",
     "iopub.status.idle": "2025-12-11T09:53:02.562612Z",
     "shell.execute_reply": "2025-12-11T09:53:02.562070Z"
    },
    "papermill": {
     "duration": 0.009164,
     "end_time": "2025-12-11T09:53:02.563913",
     "exception": false,
     "start_time": "2025-12-11T09:53:02.554749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RGBDepthEncoders(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # RGB EfficientNet\n",
    "        rgb = models.efficientnet_b0(weights=None)  # hoặc weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1\n",
    "        # Depth EfficientNet\n",
    "        depth = models.efficientnet_b0(weights=None)\n",
    "\n",
    "        # Sửa input depth thành 1 kênh\n",
    "        depth.features[0][0] = nn.Conv2d(\n",
    "            1, 32,  # EfficientNet-B0 input conv out_channels = 32\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "        # Bỏ phần classifier, chỉ lấy feature map\n",
    "        rgb.classifier = nn.Identity()\n",
    "        depth.classifier = nn.Identity()\n",
    "\n",
    "        self.rgb_encoder = rgb\n",
    "        self.depth_encoder = depth\n",
    "\n",
    "    def forward(self, rgb, depth):\n",
    "        z_rgb = self.rgb_encoder(rgb)\n",
    "        z_dep = self.depth_encoder(depth)\n",
    "        return z_rgb, z_dep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf9f193d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T09:53:02.568296Z",
     "iopub.status.busy": "2025-12-11T09:53:02.567929Z",
     "iopub.status.idle": "2025-12-11T09:53:02.573772Z",
     "shell.execute_reply": "2025-12-11T09:53:02.573224Z"
    },
    "papermill": {
     "duration": 0.0093,
     "end_time": "2025-12-11T09:53:02.574759",
     "exception": false,
     "start_time": "2025-12-11T09:53:02.565459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def simclr_contrastive_loss(z1, z2, temperature=0.1):\n",
    "    \"\"\"\n",
    "    z1, z2: [batch_size, feature_dim]\n",
    "    \"\"\"\n",
    "    batch_size = z1.size(0)\n",
    "\n",
    "    # normalize\n",
    "    z1 = F.normalize(z1, dim=1)\n",
    "    z2 = F.normalize(z2, dim=1)\n",
    "\n",
    "    # concatenate tất cả feature để tính similarity\n",
    "    z = torch.cat([z1, z2], dim=0)  # [2*B, D]\n",
    "\n",
    "    # similarity matrix\n",
    "    sim = torch.matmul(z, z.T) / temperature  # [2B, 2B]\n",
    "\n",
    "    # mask để loại bỏ similarity của cùng 1 sample\n",
    "    mask = (~torch.eye(2*batch_size, 2*batch_size, dtype=bool)).to(z.device)\n",
    "\n",
    "    sim_masked = sim[mask].view(2*batch_size, -1)  # loại bỏ self-similarity\n",
    "\n",
    "    # positive pairs: i-th của z1 ↔ i-th của z2\n",
    "    pos = torch.exp(torch.sum(z1 * z2, dim=-1) / temperature)\n",
    "    pos = torch.cat([pos, pos], dim=0)  # [2B]\n",
    "\n",
    "    # loss = -log(pos / sum(exp(similarities)))\n",
    "    loss = -torch.log(pos / sim_masked.exp().sum(dim=1))\n",
    "    return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aaacf7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T09:53:02.578900Z",
     "iopub.status.busy": "2025-12-11T09:53:02.578632Z",
     "iopub.status.idle": "2025-12-11T09:53:02.583690Z",
     "shell.execute_reply": "2025-12-11T09:53:02.583200Z"
    },
    "papermill": {
     "duration": 0.008449,
     "end_time": "2025-12-11T09:53:02.584754",
     "exception": false,
     "start_time": "2025-12-11T09:53:02.576305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RGBDepthTrainer:\n",
    "    def __init__(self, device=\"cuda\"):\n",
    "        self.device = device\n",
    "        self.model = RGBDepthEncoders().to(device)\n",
    "        self.opt = torch.optim.Adam(self.model.parameters(), lr=1e-4)\n",
    "\n",
    "    def step(self, rgb1, rgb2, dep1, dep2):\n",
    "        rgb1, rgb2 = rgb1.to(self.device), rgb2.to(self.device)\n",
    "        dep1, dep2 = dep1.to(self.device), dep2.to(self.device)\n",
    "\n",
    "        z_r1, z_d1 = self.model(rgb1, dep1)\n",
    "        z_r2, z_d2 = self.model(rgb2, dep2)\n",
    "\n",
    "        # multi-view contrastive loss\n",
    "        loss_rgb = simclr_contrastive_loss(z_r1, z_r2)\n",
    "        loss_depth = simclr_contrastive_loss(z_d1, z_d2)\n",
    "        loss_rgb_depth = simclr_contrastive_loss(z_r1, z_d1)\n",
    "\n",
    "        loss = (loss_rgb + loss_depth + loss_rgb_depth) / 3\n",
    "\n",
    "        self.opt.zero_grad()\n",
    "        loss.backward()\n",
    "        self.opt.step()\n",
    "\n",
    "        return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80d98079",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T09:53:02.588685Z",
     "iopub.status.busy": "2025-12-11T09:53:02.588448Z",
     "iopub.status.idle": "2025-12-11T11:55:41.762775Z",
     "shell.execute_reply": "2025-12-11T11:55:41.761684Z"
    },
    "papermill": {
     "duration": 7359.178316,
     "end_time": "2025-12-11T11:55:41.764563",
     "exception": false,
     "start_time": "2025-12-11T09:53:02.586247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matched pairs: 50000\n",
      "Epoch 0 | Batch 100 | Current batch loss: 3.4164\n",
      "Epoch 0 | Batch 200 | Current batch loss: 2.6635\n",
      "Epoch 0 | Batch 300 | Current batch loss: 2.4087\n",
      "Epoch 0 | Batch 400 | Current batch loss: 2.1693\n",
      "Epoch 0 | Batch 500 | Current batch loss: 1.8476\n",
      "Epoch 0 | Batch 600 | Current batch loss: 1.6712\n",
      "Epoch 0 | Batch 700 | Current batch loss: 1.7735\n",
      "Epoch 0 | Batch 800 | Current batch loss: 1.6547\n",
      "Epoch 0 | Batch 900 | Current batch loss: 1.6577\n",
      "Epoch 0 | Batch 1000 | Current batch loss: 1.4844\n",
      "Epoch 0 | Batch 1100 | Current batch loss: 1.3652\n",
      "Epoch 0 | Batch 1200 | Current batch loss: 1.3403\n",
      "Epoch 0 | Batch 1300 | Current batch loss: 1.5455\n",
      "Epoch 0 | Batch 1400 | Current batch loss: 1.4993\n",
      "Epoch 0 | Batch 1500 | Current batch loss: 1.3683\n",
      "Epoch 0 completed — Average loss: 1.9242\n",
      "Epoch 1 | Batch 100 | Current batch loss: 1.1862\n",
      "Epoch 1 | Batch 200 | Current batch loss: 1.0763\n",
      "Epoch 1 | Batch 300 | Current batch loss: 1.2770\n",
      "Epoch 1 | Batch 400 | Current batch loss: 1.2892\n",
      "Epoch 1 | Batch 500 | Current batch loss: 1.2729\n",
      "Epoch 1 | Batch 600 | Current batch loss: 1.0857\n",
      "Epoch 1 | Batch 700 | Current batch loss: 1.2997\n",
      "Epoch 1 | Batch 800 | Current batch loss: 1.2315\n",
      "Epoch 1 | Batch 900 | Current batch loss: 1.1668\n",
      "Epoch 1 | Batch 1000 | Current batch loss: 1.1887\n",
      "Epoch 1 | Batch 1100 | Current batch loss: 1.1522\n",
      "Epoch 1 | Batch 1200 | Current batch loss: 1.0651\n",
      "Epoch 1 | Batch 1300 | Current batch loss: 1.0916\n",
      "Epoch 1 | Batch 1400 | Current batch loss: 1.0358\n",
      "Epoch 1 | Batch 1500 | Current batch loss: 1.0358\n",
      "Epoch 1 completed — Average loss: 1.1811\n",
      "Epoch 2 | Batch 100 | Current batch loss: 1.1114\n",
      "Epoch 2 | Batch 200 | Current batch loss: 1.0043\n",
      "Epoch 2 | Batch 300 | Current batch loss: 0.9614\n",
      "Epoch 2 | Batch 400 | Current batch loss: 1.1441\n",
      "Epoch 2 | Batch 500 | Current batch loss: 0.9303\n",
      "Epoch 2 | Batch 600 | Current batch loss: 0.9011\n",
      "Epoch 2 | Batch 700 | Current batch loss: 0.9901\n",
      "Epoch 2 | Batch 800 | Current batch loss: 0.9459\n",
      "Epoch 2 | Batch 900 | Current batch loss: 0.8059\n",
      "Epoch 2 | Batch 1000 | Current batch loss: 1.1285\n",
      "Epoch 2 | Batch 1100 | Current batch loss: 1.0398\n",
      "Epoch 2 | Batch 1200 | Current batch loss: 0.8240\n",
      "Epoch 2 | Batch 1300 | Current batch loss: 0.7838\n",
      "Epoch 2 | Batch 1400 | Current batch loss: 0.9939\n",
      "Epoch 2 | Batch 1500 | Current batch loss: 0.8621\n",
      "Epoch 2 completed — Average loss: 0.9711\n",
      "Epoch 3 | Batch 100 | Current batch loss: 0.8940\n",
      "Epoch 3 | Batch 200 | Current batch loss: 0.7496\n",
      "Epoch 3 | Batch 300 | Current batch loss: 0.7964\n",
      "Epoch 3 | Batch 400 | Current batch loss: 0.8032\n",
      "Epoch 3 | Batch 500 | Current batch loss: 0.7625\n",
      "Epoch 3 | Batch 600 | Current batch loss: 0.8393\n",
      "Epoch 3 | Batch 700 | Current batch loss: 0.9279\n",
      "Epoch 3 | Batch 800 | Current batch loss: 0.9325\n",
      "Epoch 3 | Batch 900 | Current batch loss: 0.8076\n",
      "Epoch 3 | Batch 1000 | Current batch loss: 0.8396\n",
      "Epoch 3 | Batch 1100 | Current batch loss: 0.9116\n",
      "Epoch 3 | Batch 1200 | Current batch loss: 0.6723\n",
      "Epoch 3 | Batch 1300 | Current batch loss: 0.7002\n",
      "Epoch 3 | Batch 1400 | Current batch loss: 0.6865\n",
      "Epoch 3 | Batch 1500 | Current batch loss: 0.6775\n",
      "Epoch 3 completed — Average loss: 0.8160\n",
      "Epoch 4 | Batch 100 | Current batch loss: 0.7915\n",
      "Epoch 4 | Batch 200 | Current batch loss: 0.6511\n",
      "Epoch 4 | Batch 300 | Current batch loss: 0.6918\n",
      "Epoch 4 | Batch 400 | Current batch loss: 0.6592\n",
      "Epoch 4 | Batch 500 | Current batch loss: 0.7139\n",
      "Epoch 4 | Batch 600 | Current batch loss: 0.6565\n",
      "Epoch 4 | Batch 700 | Current batch loss: 0.5847\n",
      "Epoch 4 | Batch 800 | Current batch loss: 0.6533\n",
      "Epoch 4 | Batch 900 | Current batch loss: 0.8150\n",
      "Epoch 4 | Batch 1000 | Current batch loss: 0.5462\n",
      "Epoch 4 | Batch 1100 | Current batch loss: 0.7313\n",
      "Epoch 4 | Batch 1200 | Current batch loss: 0.6515\n",
      "Epoch 4 | Batch 1300 | Current batch loss: 0.6537\n",
      "Epoch 4 | Batch 1400 | Current batch loss: 0.5536\n",
      "Epoch 4 | Batch 1500 | Current batch loss: 0.5554\n",
      "Epoch 4 completed — Average loss: 0.6910\n",
      "Saved RGB encoder to /kaggle/working/rgb_encoder_epoch5.pth\n",
      "Saved Depth encoder to /kaggle/working/depth_encoder_epoch5.pth\n",
      "Epoch 5 | Batch 100 | Current batch loss: 0.5573\n",
      "Epoch 5 | Batch 200 | Current batch loss: 0.6338\n",
      "Epoch 5 | Batch 300 | Current batch loss: 0.5637\n",
      "Epoch 5 | Batch 400 | Current batch loss: 0.6237\n",
      "Epoch 5 | Batch 500 | Current batch loss: 0.5794\n",
      "Epoch 5 | Batch 600 | Current batch loss: 0.7365\n",
      "Epoch 5 | Batch 700 | Current batch loss: 0.5424\n",
      "Epoch 5 | Batch 800 | Current batch loss: 0.5780\n",
      "Epoch 5 | Batch 900 | Current batch loss: 0.4286\n",
      "Epoch 5 | Batch 1000 | Current batch loss: 0.4818\n",
      "Epoch 5 | Batch 1100 | Current batch loss: 0.5462\n",
      "Epoch 5 | Batch 1200 | Current batch loss: 0.6079\n",
      "Epoch 5 | Batch 1300 | Current batch loss: 0.4854\n",
      "Epoch 5 | Batch 1400 | Current batch loss: 0.5831\n",
      "Epoch 5 | Batch 1500 | Current batch loss: 0.4715\n",
      "Epoch 5 completed — Average loss: 0.5785\n",
      "Epoch 6 | Batch 100 | Current batch loss: 0.4787\n",
      "Epoch 6 | Batch 200 | Current batch loss: 0.4195\n",
      "Epoch 6 | Batch 300 | Current batch loss: 0.4461\n",
      "Epoch 6 | Batch 400 | Current batch loss: 0.6467\n",
      "Epoch 6 | Batch 500 | Current batch loss: 0.3894\n",
      "Epoch 6 | Batch 600 | Current batch loss: 0.5466\n",
      "Epoch 6 | Batch 700 | Current batch loss: 0.4726\n",
      "Epoch 6 | Batch 800 | Current batch loss: 0.5011\n",
      "Epoch 6 | Batch 900 | Current batch loss: 0.4721\n",
      "Epoch 6 | Batch 1000 | Current batch loss: 0.6721\n",
      "Epoch 6 | Batch 1100 | Current batch loss: 0.3984\n",
      "Epoch 6 | Batch 1200 | Current batch loss: 0.4745\n",
      "Epoch 6 | Batch 1300 | Current batch loss: 0.6047\n",
      "Epoch 6 | Batch 1400 | Current batch loss: 0.3768\n",
      "Epoch 6 | Batch 1500 | Current batch loss: 0.3532\n",
      "Epoch 6 completed — Average loss: 0.4903\n",
      "Epoch 7 | Batch 100 | Current batch loss: 0.5040\n",
      "Epoch 7 | Batch 200 | Current batch loss: 0.3204\n",
      "Epoch 7 | Batch 300 | Current batch loss: 0.4357\n",
      "Epoch 7 | Batch 400 | Current batch loss: 0.3313\n",
      "Epoch 7 | Batch 500 | Current batch loss: 0.3351\n",
      "Epoch 7 | Batch 600 | Current batch loss: 0.4019\n",
      "Epoch 7 | Batch 700 | Current batch loss: 0.4626\n",
      "Epoch 7 | Batch 800 | Current batch loss: 0.4461\n",
      "Epoch 7 | Batch 900 | Current batch loss: 0.3502\n",
      "Epoch 7 | Batch 1000 | Current batch loss: 0.3610\n",
      "Epoch 7 | Batch 1100 | Current batch loss: 0.3855\n",
      "Epoch 7 | Batch 1200 | Current batch loss: 0.2808\n",
      "Epoch 7 | Batch 1300 | Current batch loss: 0.4117\n",
      "Epoch 7 | Batch 1400 | Current batch loss: 0.4316\n",
      "Epoch 7 | Batch 1500 | Current batch loss: 0.3022\n",
      "Epoch 7 completed — Average loss: 0.4209\n",
      "Epoch 8 | Batch 100 | Current batch loss: 0.2977\n",
      "Epoch 8 | Batch 200 | Current batch loss: 0.2717\n",
      "Epoch 8 | Batch 300 | Current batch loss: 0.3955\n",
      "Epoch 8 | Batch 400 | Current batch loss: 0.3684\n",
      "Epoch 8 | Batch 500 | Current batch loss: 0.3822\n",
      "Epoch 8 | Batch 600 | Current batch loss: 0.4251\n",
      "Epoch 8 | Batch 700 | Current batch loss: 0.4146\n",
      "Epoch 8 | Batch 800 | Current batch loss: 0.2789\n",
      "Epoch 8 | Batch 900 | Current batch loss: 0.2916\n",
      "Epoch 8 | Batch 1000 | Current batch loss: 0.3385\n",
      "Epoch 8 | Batch 1100 | Current batch loss: 0.3198\n",
      "Epoch 8 | Batch 1200 | Current batch loss: 0.2940\n",
      "Epoch 8 | Batch 1300 | Current batch loss: 0.2939\n",
      "Epoch 8 | Batch 1400 | Current batch loss: 0.3490\n",
      "Epoch 8 | Batch 1500 | Current batch loss: 0.3260\n",
      "Epoch 8 completed — Average loss: 0.3666\n",
      "Epoch 9 | Batch 100 | Current batch loss: 0.4854\n",
      "Epoch 9 | Batch 200 | Current batch loss: 0.2165\n",
      "Epoch 9 | Batch 300 | Current batch loss: 0.2395\n",
      "Epoch 9 | Batch 400 | Current batch loss: 0.3091\n",
      "Epoch 9 | Batch 500 | Current batch loss: 0.2661\n",
      "Epoch 9 | Batch 600 | Current batch loss: 0.2987\n",
      "Epoch 9 | Batch 700 | Current batch loss: 0.2537\n",
      "Epoch 9 | Batch 800 | Current batch loss: 0.3099\n",
      "Epoch 9 | Batch 900 | Current batch loss: 0.3079\n",
      "Epoch 9 | Batch 1000 | Current batch loss: 0.3465\n",
      "Epoch 9 | Batch 1100 | Current batch loss: 0.2581\n",
      "Epoch 9 | Batch 1200 | Current batch loss: 0.2316\n",
      "Epoch 9 | Batch 1300 | Current batch loss: 0.4552\n",
      "Epoch 9 | Batch 1400 | Current batch loss: 0.4164\n",
      "Epoch 9 | Batch 1500 | Current batch loss: 0.3562\n",
      "Epoch 9 completed — Average loss: 0.3171\n",
      "Saved RGB encoder to /kaggle/working/rgb_encoder_epoch10.pth\n",
      "Saved Depth encoder to /kaggle/working/depth_encoder_epoch10.pth\n",
      "Epoch 10 | Batch 100 | Current batch loss: 0.2610\n",
      "Epoch 10 | Batch 200 | Current batch loss: 0.2314\n",
      "Epoch 10 | Batch 300 | Current batch loss: 0.2847\n",
      "Epoch 10 | Batch 400 | Current batch loss: 0.3210\n",
      "Epoch 10 | Batch 500 | Current batch loss: 0.2703\n",
      "Epoch 10 | Batch 600 | Current batch loss: 0.3024\n",
      "Epoch 10 | Batch 700 | Current batch loss: 0.2904\n",
      "Epoch 10 | Batch 800 | Current batch loss: 0.2781\n",
      "Epoch 10 | Batch 900 | Current batch loss: 0.2689\n",
      "Epoch 10 | Batch 1000 | Current batch loss: 0.3041\n",
      "Epoch 10 | Batch 1100 | Current batch loss: 0.2563\n",
      "Epoch 10 | Batch 1200 | Current batch loss: 0.4692\n",
      "Epoch 10 | Batch 1300 | Current batch loss: 0.4160\n",
      "Epoch 10 | Batch 1400 | Current batch loss: 0.2856\n",
      "Epoch 10 | Batch 1500 | Current batch loss: 0.3503\n",
      "Epoch 10 completed — Average loss: 0.2854\n",
      "Epoch 11 | Batch 100 | Current batch loss: 0.3044\n",
      "Epoch 11 | Batch 200 | Current batch loss: 0.2350\n",
      "Epoch 11 | Batch 300 | Current batch loss: 0.2053\n",
      "Epoch 11 | Batch 400 | Current batch loss: 0.2876\n",
      "Epoch 11 | Batch 500 | Current batch loss: 0.2392\n",
      "Epoch 11 | Batch 600 | Current batch loss: 0.2840\n",
      "Epoch 11 | Batch 700 | Current batch loss: 0.2026\n",
      "Epoch 11 | Batch 800 | Current batch loss: 0.2883\n",
      "Epoch 11 | Batch 900 | Current batch loss: 0.2797\n",
      "Epoch 11 | Batch 1000 | Current batch loss: 0.3033\n",
      "Epoch 11 | Batch 1100 | Current batch loss: 0.2733\n",
      "Epoch 11 | Batch 1200 | Current batch loss: 0.3749\n",
      "Epoch 11 | Batch 1300 | Current batch loss: 0.3872\n",
      "Epoch 11 | Batch 1400 | Current batch loss: 0.2574\n",
      "Epoch 11 | Batch 1500 | Current batch loss: 0.2074\n",
      "Epoch 11 completed — Average loss: 0.2554\n",
      "Epoch 12 | Batch 100 | Current batch loss: 0.2224\n",
      "Epoch 12 | Batch 200 | Current batch loss: 0.2193\n",
      "Epoch 12 | Batch 300 | Current batch loss: 0.2787\n",
      "Epoch 12 | Batch 400 | Current batch loss: 0.1674\n",
      "Epoch 12 | Batch 500 | Current batch loss: 0.1549\n",
      "Epoch 12 | Batch 600 | Current batch loss: 0.2922\n",
      "Epoch 12 | Batch 700 | Current batch loss: 0.3509\n",
      "Epoch 12 | Batch 800 | Current batch loss: 0.1987\n",
      "Epoch 12 | Batch 900 | Current batch loss: 0.2148\n",
      "Epoch 12 | Batch 1000 | Current batch loss: 0.2691\n",
      "Epoch 12 | Batch 1100 | Current batch loss: 0.2049\n",
      "Epoch 12 | Batch 1200 | Current batch loss: 0.2431\n",
      "Epoch 12 | Batch 1300 | Current batch loss: 0.2011\n",
      "Epoch 12 | Batch 1400 | Current batch loss: 0.1967\n",
      "Epoch 12 | Batch 1500 | Current batch loss: 0.2088\n",
      "Epoch 12 completed — Average loss: 0.2309\n",
      "Epoch 13 | Batch 100 | Current batch loss: 0.1936\n",
      "Epoch 13 | Batch 200 | Current batch loss: 0.1607\n",
      "Epoch 13 | Batch 300 | Current batch loss: 0.2928\n",
      "Epoch 13 | Batch 400 | Current batch loss: 0.1345\n",
      "Epoch 13 | Batch 500 | Current batch loss: 0.2480\n",
      "Epoch 13 | Batch 600 | Current batch loss: 0.1949\n",
      "Epoch 13 | Batch 700 | Current batch loss: 0.2916\n",
      "Epoch 13 | Batch 800 | Current batch loss: 0.2929\n",
      "Epoch 13 | Batch 900 | Current batch loss: 0.1834\n",
      "Epoch 13 | Batch 1000 | Current batch loss: 0.2610\n",
      "Epoch 13 | Batch 1100 | Current batch loss: 0.1924\n",
      "Epoch 13 | Batch 1200 | Current batch loss: 0.2125\n",
      "Epoch 13 | Batch 1300 | Current batch loss: 0.2592\n",
      "Epoch 13 | Batch 1400 | Current batch loss: 0.2015\n",
      "Epoch 13 | Batch 1500 | Current batch loss: 0.2292\n",
      "Epoch 13 completed — Average loss: 0.2108\n",
      "Epoch 14 | Batch 100 | Current batch loss: 0.1371\n",
      "Epoch 14 | Batch 200 | Current batch loss: 0.1853\n",
      "Epoch 14 | Batch 300 | Current batch loss: 0.1266\n",
      "Epoch 14 | Batch 400 | Current batch loss: 0.2036\n",
      "Epoch 14 | Batch 500 | Current batch loss: 0.1618\n",
      "Epoch 14 | Batch 600 | Current batch loss: 0.2141\n",
      "Epoch 14 | Batch 700 | Current batch loss: 0.2765\n",
      "Epoch 14 | Batch 800 | Current batch loss: 0.1482\n",
      "Epoch 14 | Batch 900 | Current batch loss: 0.3143\n",
      "Epoch 14 | Batch 1000 | Current batch loss: 0.2327\n",
      "Epoch 14 | Batch 1100 | Current batch loss: 0.2217\n",
      "Epoch 14 | Batch 1200 | Current batch loss: 0.2162\n",
      "Epoch 14 | Batch 1300 | Current batch loss: 0.1727\n",
      "Epoch 14 | Batch 1400 | Current batch loss: 0.1593\n",
      "Epoch 14 | Batch 1500 | Current batch loss: 0.1423\n",
      "Epoch 14 completed — Average loss: 0.1945\n",
      "Saved RGB encoder to /kaggle/working/rgb_encoder_epoch15.pth\n",
      "Saved Depth encoder to /kaggle/working/depth_encoder_epoch15.pth\n",
      "Epoch 15 | Batch 100 | Current batch loss: 0.1768\n",
      "Epoch 15 | Batch 200 | Current batch loss: 0.1459\n",
      "Epoch 15 | Batch 300 | Current batch loss: 0.2488\n",
      "Epoch 15 | Batch 400 | Current batch loss: 0.2555\n",
      "Epoch 15 | Batch 500 | Current batch loss: 0.1245\n",
      "Epoch 15 | Batch 600 | Current batch loss: 0.2076\n",
      "Epoch 15 | Batch 700 | Current batch loss: 0.1836\n",
      "Epoch 15 | Batch 800 | Current batch loss: 0.1695\n",
      "Epoch 15 | Batch 900 | Current batch loss: 0.1511\n",
      "Epoch 15 | Batch 1000 | Current batch loss: 0.1118\n",
      "Epoch 15 | Batch 1100 | Current batch loss: 0.1887\n",
      "Epoch 15 | Batch 1200 | Current batch loss: 0.1196\n",
      "Epoch 15 | Batch 1300 | Current batch loss: 0.1668\n",
      "Epoch 15 | Batch 1400 | Current batch loss: 0.1938\n",
      "Epoch 15 | Batch 1500 | Current batch loss: 0.1419\n",
      "Epoch 15 completed — Average loss: 0.1800\n",
      "Epoch 16 | Batch 100 | Current batch loss: 0.1144\n",
      "Epoch 16 | Batch 200 | Current batch loss: 0.2417\n",
      "Epoch 16 | Batch 300 | Current batch loss: 0.1970\n",
      "Epoch 16 | Batch 400 | Current batch loss: 0.2365\n",
      "Epoch 16 | Batch 500 | Current batch loss: 0.2197\n",
      "Epoch 16 | Batch 600 | Current batch loss: 0.1192\n",
      "Epoch 16 | Batch 700 | Current batch loss: 0.1249\n",
      "Epoch 16 | Batch 800 | Current batch loss: 0.2137\n",
      "Epoch 16 | Batch 900 | Current batch loss: 0.1556\n",
      "Epoch 16 | Batch 1000 | Current batch loss: 0.1567\n",
      "Epoch 16 | Batch 1100 | Current batch loss: 0.1018\n",
      "Epoch 16 | Batch 1200 | Current batch loss: 0.1858\n",
      "Epoch 16 | Batch 1300 | Current batch loss: 0.1303\n",
      "Epoch 16 | Batch 1400 | Current batch loss: 0.1327\n",
      "Epoch 16 | Batch 1500 | Current batch loss: 0.1272\n",
      "Epoch 16 completed — Average loss: 0.1673\n",
      "Epoch 17 | Batch 100 | Current batch loss: 0.2438\n",
      "Epoch 17 | Batch 200 | Current batch loss: 0.1451\n",
      "Epoch 17 | Batch 300 | Current batch loss: 0.1707\n",
      "Epoch 17 | Batch 400 | Current batch loss: 0.1743\n",
      "Epoch 17 | Batch 500 | Current batch loss: 0.1136\n",
      "Epoch 17 | Batch 600 | Current batch loss: 0.1626\n",
      "Epoch 17 | Batch 700 | Current batch loss: 0.1247\n",
      "Epoch 17 | Batch 800 | Current batch loss: 0.1073\n",
      "Epoch 17 | Batch 900 | Current batch loss: 0.1230\n",
      "Epoch 17 | Batch 1000 | Current batch loss: 0.2294\n",
      "Epoch 17 | Batch 1100 | Current batch loss: 0.1352\n",
      "Epoch 17 | Batch 1200 | Current batch loss: 0.1767\n",
      "Epoch 17 | Batch 1300 | Current batch loss: 0.2238\n",
      "Epoch 17 | Batch 1400 | Current batch loss: 0.1800\n",
      "Epoch 17 | Batch 1500 | Current batch loss: 0.1354\n",
      "Epoch 17 completed — Average loss: 0.1575\n",
      "Epoch 18 | Batch 100 | Current batch loss: 0.1749\n",
      "Epoch 18 | Batch 200 | Current batch loss: 0.1633\n",
      "Epoch 18 | Batch 300 | Current batch loss: 0.1182\n",
      "Epoch 18 | Batch 400 | Current batch loss: 0.1340\n",
      "Epoch 18 | Batch 500 | Current batch loss: 0.1756\n",
      "Epoch 18 | Batch 600 | Current batch loss: 0.1300\n",
      "Epoch 18 | Batch 700 | Current batch loss: 0.0910\n",
      "Epoch 18 | Batch 800 | Current batch loss: 0.1218\n",
      "Epoch 18 | Batch 900 | Current batch loss: 0.1900\n",
      "Epoch 18 | Batch 1000 | Current batch loss: 0.1226\n",
      "Epoch 18 | Batch 1100 | Current batch loss: 0.1443\n",
      "Epoch 18 | Batch 1200 | Current batch loss: 0.1321\n",
      "Epoch 18 | Batch 1300 | Current batch loss: 0.1323\n",
      "Epoch 18 | Batch 1400 | Current batch loss: 0.1494\n",
      "Epoch 18 | Batch 1500 | Current batch loss: 0.1216\n",
      "Epoch 18 completed — Average loss: 0.1470\n",
      "Epoch 19 | Batch 100 | Current batch loss: 0.0755\n",
      "Epoch 19 | Batch 200 | Current batch loss: 0.1972\n",
      "Epoch 19 | Batch 300 | Current batch loss: 0.1074\n",
      "Epoch 19 | Batch 400 | Current batch loss: 0.1246\n",
      "Epoch 19 | Batch 500 | Current batch loss: 0.1423\n",
      "Epoch 19 | Batch 600 | Current batch loss: 0.1475\n",
      "Epoch 19 | Batch 700 | Current batch loss: 0.1888\n",
      "Epoch 19 | Batch 800 | Current batch loss: 0.1259\n",
      "Epoch 19 | Batch 900 | Current batch loss: 0.1417\n",
      "Epoch 19 | Batch 1000 | Current batch loss: 0.1163\n",
      "Epoch 19 | Batch 1100 | Current batch loss: 0.0731\n",
      "Epoch 19 | Batch 1200 | Current batch loss: 0.0698\n",
      "Epoch 19 | Batch 1300 | Current batch loss: 0.1100\n",
      "Epoch 19 | Batch 1400 | Current batch loss: 0.1354\n",
      "Epoch 19 | Batch 1500 | Current batch loss: 0.0980\n",
      "Epoch 19 completed — Average loss: 0.1390\n",
      "Saved RGB encoder to /kaggle/working/rgb_encoder_epoch20.pth\n",
      "Saved Depth encoder to /kaggle/working/depth_encoder_epoch20.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Dataset, Trainer đã được định nghĩa trước\n",
    "\n",
    "dataset = RGBDepthDataset(\n",
    "    rgb_dir=\"/kaggle/input/midasz-face/celeba_rgb_output\",\n",
    "    depth_dir=\"/kaggle/input/midasz-face/celeba_depth\",\n",
    "    image_size=128\n",
    ")\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=2, drop_last=True)\n",
    "trainer = RGBDepthTrainer(device=\"cuda\")\n",
    "\n",
    "save_dir = \"/kaggle/working\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for epoch in range(20):\n",
    "    total_loss = 0\n",
    "    for i, (rgb1, rgb2, dep1, dep2) in enumerate(loader):\n",
    "        loss = trainer.step(rgb1, rgb2, dep1, dep2)\n",
    "        total_loss += loss\n",
    "\n",
    "        # In log mỗi 100 batch\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Epoch {epoch} | Batch {i+1} | Current batch loss: {loss:.4f}\")\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    print(f\"Epoch {epoch} completed — Average loss: {avg_loss:.4f}\")\n",
    "\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        rgb_path = os.path.join(save_dir, f\"rgb_encoder_epoch{epoch+1}.pth\")\n",
    "        depth_path = os.path.join(save_dir, f\"depth_encoder_epoch{epoch+1}.pth\")\n",
    "        torch.save(trainer.model.rgb_encoder.state_dict(), rgb_path)\n",
    "        torch.save(trainer.model.depth_encoder.state_dict(), depth_path)\n",
    "        print(f\"Saved RGB encoder to {rgb_path}\")\n",
    "        print(f\"Saved Depth encoder to {depth_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8966391,
     "sourceId": 14083541,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7374.940583,
   "end_time": "2025-12-11T11:55:44.434598",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-11T09:52:49.494015",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
